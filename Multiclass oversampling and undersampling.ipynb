{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Imbalanced Data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "random_state=25\n",
    "x,y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                          n_clusters_per_class=2,class_sep=2,flip_y=0,weights=[0.9,0.1], random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples \n",
      " 0    900\n",
      "1    100\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict(x=x[:,0], y=x[:,1], label=y))\n",
    "print(\"Total number of examples \\n\",df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a standard practice, it is best to split data in training and validation data and then perform oversampling or undersampling on the training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate input features and target\n",
    "y = df.label\n",
    "X = df.drop('label', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [resample](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html) in sklearn\n",
    "Duplicates existing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled train data\n",
      " 1    677\n",
      "0    677\n",
      "Name: label, dtype: int64\n",
      "Unaltered test data\n",
      " 0    223\n",
      "1     27\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "negative = X[X.label==0]\n",
    "positive = X[X.label==1]\n",
    "\n",
    "# upsample minority\n",
    "positive_upsampled = resample(positive,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(negative), # match number in majority class\n",
    "                          random_state=random_state) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled_train_data = pd.concat([negative, positive_upsampled])\n",
    "# ready test data\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "# check new class counts\n",
    "print(\"Upsampled train data\\n\",upsampled_train_data.label.value_counts())\n",
    "print(\"Unaltered test data\\n\",test.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proof that resample duplicates records\n",
    "ones=upsampled_train_data.loc[upsampled_train_data['label'] == 1]\n",
    "# Select duplicate rows except first occurrence based on all columns\n",
    "duplicate = ones[ones.duplicated()]\n",
    "elements=[]\n",
    "array=duplicate[['x','y']].values\n",
    "for ele in array:\n",
    "    if(ele[0]==1.5521948346327128 and ele[1]==1.692681622419994):\n",
    "        elements.append(ele)\n",
    "len(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [Random Oversampler](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html) in imblearn\n",
    "Oversampling by picking samples at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of ROS \n",
      " 1    677\n",
      "0    677\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=random_state)\n",
    "\n",
    "x_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(dict(x=x_ros[:,0], y=x_ros[:,1], label=y_ros))\n",
    "print(\"Results of ROS \\n\",df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html) in imblearn and [related techniques](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html#sphx-glr-auto-examples-over-sampling-plot-comparison-over-sampling-py)\n",
    "Synthetic examples created using nearest neighbour approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of SMOTE \n",
      " 1    677\n",
      "0    677\n",
      "Name: label, dtype: int64\n",
      "Results of Borderline SMOTE \n",
      " 0    677\n",
      "1     73\n",
      "Name: label, dtype: int64\n",
      "Results of SVM SMOTE \n",
      " 0    677\n",
      "1    411\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, SVMSMOTE, SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=random_state)\n",
    "bsm1=BorderlineSMOTE(random_state=random_state, kind='borderline-1')\n",
    "svmsm=SVMSMOTE(random_state=random_state)\n",
    "\n",
    "x_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "x_bsmote1, y_bsmote1 = bsm1.fit_resample(X_train, y_train)\n",
    "x_svmsm, y_svmsm = svmsm.fit_resample(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(dict(x=x_res[:,0], y=x_res[:,1], label=y_res))\n",
    "print(\"Results of SMOTE \\n\",df.label.value_counts())\n",
    "df = pd.DataFrame(dict(x=x_bsmote1[:,0], y=x_bsmote1[:,1], label=y_bsmote1))\n",
    "print(\"Results of Borderline SMOTE \\n\",df.label.value_counts())\n",
    "df = pd.DataFrame(dict(x=x_svmsm[:,0], y=x_svmsm[:,1], label=y_svmsm))\n",
    "print(\"Results of SVM SMOTE \\n\",df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADASYN](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html) and [SMOTENC](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTENC.html) are some more approaches, but I have found them to cause errors while using the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [resample](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html) in sklearn\n",
    "Undersampling majority class by randomly picking off elements in majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73\n",
       "0    73\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "negative = X[X.label==0]\n",
    "positive = X[X.label==1]\n",
    "\n",
    "negative_downsampled = resample(negative,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(positive), # match minority\n",
    "                                random_state = random_state) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([negative_downsampled, positive])\n",
    "\n",
    "# checking counts\n",
    "downsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Undersampling](https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.under_sampling) using the imblearn API\n",
    "## A combination of oversampling and oversampling techniques like [SMOTEEN and SMOTETomek](https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.under_sampling) also gives good results\n",
    "### Check out this [Towards data science](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) link too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
